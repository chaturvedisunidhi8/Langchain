{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8107fb1",
   "metadata": {},
   "source": [
    "Ollama\n",
    "\n",
    "Ollama supports embedding models, making it possible to build retrieval augmented generation (RAG) applications that combine text prompts with existing documents or other data.\n",
    "\n",
    "NOTE--- while having a new file always choose kernel python venv by going on option selecting another kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeb0dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunidhi\\AppData\\Local\\Temp\\ipykernel_7852\\2898541343.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings=OllamaEmbeddings(model=\"gemma:2b\")\n"
     ]
    }
   ],
   "source": [
    "##create embeddings as we did in open ai\n",
    "embeddings=OllamaEmbeddings(model=\"gemma:2b\")\n",
    "##by default it uses Llama2 model to use your model which you installed  recently,pass it over here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ffeb154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(base_url='http://localhost:11434', model='gemma:2b', embed_instruction='passage: ', query_instruction='query: ', mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None, show_progress=False, headers=None, model_kwargs=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4005b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=embeddings.embed_documents([     ##take list of text to embed\n",
    "    \"alpha is the first letter of greek alphabet\"\n",
    "    \"beta is the first letter of greek alphabet\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534ba043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r1[0])##2048 dimenaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fef9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.embed_documents(\"translate it ,\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0284a",
   "metadata": {},
   "source": [
    "ðŸ”¹ embed_query\n",
    "\n",
    "Use case: When you want to embed a single user query (a search question, prompt, etc.)\n",
    "\n",
    "Use case: When you want to embed multiple documents (chunks of text, database rows, passages, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d419e8",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Typical flow in a retrieval pipeline:\n",
    "\n",
    "Preprocess your dataset â†’ embed_documents() â†’ store embeddings in a vector database (like FAISS, Pinecone, Chroma).\n",
    "\n",
    "User asks a question â†’ embed_query() â†’ compare with stored embeddings â†’ retrieve most relevant docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de10a67",
   "metadata": {},
   "source": [
    "Making GENAI app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0b4a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content=\"LangSmith\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nFrameworksLangGraphLangChainPlatformsLangSmithLangGraph PlatformResources\\n\\nGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocs\\n\\nPythonLangGraphLangSmithLangChainJavaScriptLangGraphLangSmithLangChainCompany\\n\\nAboutCareersPricingGet a demoSign upShip agents with confidence.LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance â€” whether building with LangChain or not.Get a demoSign up for free\\n\\nLangSmith is now available on AWS\\xa0Marketplace.Get started\\n\\n\\nHelping top teams ship reliable agents.Find failures fast with agent observability.Quickly debug and understand non-deterministic LLM app behavior with tracing. See what your agent is doing step by step â€”then fix issues to improve latency and response quality.Get started tracing your app\\n\\n\\nEvaluate your agent's performance.Evaluate your app by saving production traces to datasets â€”\\xa0 then score performance with LLM-as-Judge evaluators. Gather human feedback from subject-matter experts to assess response relevance, correctness, harmfulness, and other criteria.Learn how to run an eval\\n\\n\\nIterate and collaborate on prompts.Experiment with models and prompts in the Playground, and compare outputs across different prompt versions. Any teammate can use the Prompt Canvas UI\\xa0to directly recommend and improve prompts. Create and test a prompt\\n\\n\\nMonitor what matters to the business.Track business-critical metrics like costs, latency, and response quality with live dashboards â€” then get alerted when problems arise and drill into root cause.See how to create a custom dashboard\\n\\n\\nWhy LLM apps need different toolingYour app thinks for itself. Understand how.LLM app traces are complex â€” packed with text, tool calls, audio, and images. Youâ€™ll need to find signal in the noise, so you can debug faster and explain behavior with confidence.Testing & observability go hand in hand.There are no guarantees with LLMs. Unified testing & observability lets you turn real user data into evaluation datasets and catch issues that traditional monitoring & testing tools would miss.Itâ€™s not just devs building anymore.From PMs to subject matter experts, everyoneâ€™s involved in building GenAI apps. Close the gap between ideas and working software by making it easy to collaborate across teams â€” whether itâ€™s through writing prompts or providing feedback on experiments.LangSmith is designed for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your AI\\xa0agents, from design to production.Get the eBookLangSmith FAQsMy application isnâ€™t written in Python or TypeScript. Will LangSmith be helpful?\\n\\nYes, you can log traces to LangSmith using a standard OpenTelemetry client to access all LangSmith features, including tracing, running evals, and prompt engineering. See the docs.How can LangSmith help with observability and evaluation?\\n\\nLangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance â€” including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback. Learn more.I canâ€™t have data leave my environment. Can I self-host LangSmith?\\n\\nYes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our documentation.Where is LangSmith data stored?\\n\\nFor Cloud SaaS, traces are stored in GCP us-central-1 or GCP europe-west4, depending on your plan. Learn more.Will LangSmith add latency to my application?\\n\\nNo, LangSmith does not add any latency to your application. In the LangSmith SDK, thereâ€™s a callback handler that sends traces to a LangSmith trace collector which runs as an async, distributed process. Additionally, if LangSmith experiences an incident, your application performance will not be disrupted.Will you train on the data that I send LangSmith?\\n\\nWe will not train on your data, and you own all rights to your data. See LangSmith Terms of Service for more information.How much does LangSmith cost?\\n\\nSee our pricing page for more information, and find a plan that works for you.Ready to start shipping \\u2028reliable agents faster?Get started with tools from the LangChain product suite for every step of the agent development lifecycle.Get a demoSign up for freeProductsLangChainLangSmithLangGraphResourcesGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogExpertsPython DocsLangGraph LangSmithLangChainJS DocsLangGraphLangSmithLangChainCompanyAboutCareersXLinkedInYouTubeMarketing AssetsSecuritySign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader=WebBaseLoader(\"https://www.langchain.com/langsmith\") ##url of langsmith\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7381b6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='LangSmith\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nFrameworksLangGraphLangChainPlatformsLangSmithLangGraph PlatformResources\\n\\nGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocs\\n\\nPythonLangGraphLangSmithLangChainJavaScriptLangGraphLangSmithLangChainCompany\\n\\nAboutCareersPricingGet a demoSign upShip agents with confidence.LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance â€” whether building with LangChain or not.Get a demoSign up for free\\n\\nLangSmith is now available on AWS\\xa0Marketplace.Get started\\n\\n\\nHelping top teams ship reliable agents.Find failures fast with agent observability.Quickly debug and understand non-deterministic LLM app behavior with tracing. See what your agent is doing step by step â€”then fix issues to improve latency and response quality.Get started tracing your app'),\n",
       " Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content=\"Evaluate your agent's performance.Evaluate your app by saving production traces to datasets â€”\\xa0 then score performance with LLM-as-Judge evaluators. Gather human feedback from subject-matter experts to assess response relevance, correctness, harmfulness, and other criteria.Learn how to run an eval\\n\\n\\nIterate and collaborate on prompts.Experiment with models and prompts in the Playground, and compare outputs across different prompt versions. Any teammate can use the Prompt Canvas UI\\xa0to directly recommend and improve prompts. Create and test a prompt\\n\\n\\nMonitor what matters to the business.Track business-critical metrics like costs, latency, and response quality with live dashboards â€” then get alerted when problems arise and drill into root cause.See how to create a custom dashboard\"),\n",
       " Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Why LLM apps need different toolingYour app thinks for itself. Understand how.LLM app traces are complex â€” packed with text, tool calls, audio, and images. Youâ€™ll need to find signal in the noise, so you can debug faster and explain behavior with confidence.Testing & observability go hand in hand.There are no guarantees with LLMs. Unified testing & observability lets you turn real user data into evaluation datasets and catch issues that traditional monitoring & testing tools would miss.Itâ€™s not just devs building anymore.From PMs to subject matter experts, everyoneâ€™s involved in building GenAI apps. Close the gap between ideas and working software by making it easy to collaborate across teams â€” whether itâ€™s through writing prompts or providing feedback on experiments.LangSmith is designed for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your'),\n",
       " Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your AI\\xa0agents, from design to production.Get the eBookLangSmith FAQsMy application isnâ€™t written in Python or TypeScript. Will LangSmith be helpful?'),\n",
       " Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Yes, you can log traces to LangSmith using a standard OpenTelemetry client to access all LangSmith features, including tracing, running evals, and prompt engineering. See the docs.How can LangSmith help with observability and evaluation?\\n\\nLangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance â€” including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback. Learn more.I canâ€™t have data leave my environment. Can I self-host LangSmith?\\n\\nYes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our documentation.Where is LangSmith data stored?'),\n",
       " Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='For Cloud SaaS, traces are stored in GCP us-central-1 or GCP europe-west4, depending on your plan. Learn more.Will LangSmith add latency to my application?\\n\\nNo, LangSmith does not add any latency to your application. In the LangSmith SDK, thereâ€™s a callback handler that sends traces to a LangSmith trace collector which runs as an async, distributed process. Additionally, if LangSmith experiences an incident, your application performance will not be disrupted.Will you train on the data that I send LangSmith?\\n\\nWe will not train on your data, and you own all rights to your data. See LangSmith Terms of Service for more information.How much does LangSmith cost?'),\n",
       " Document(metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='We will not train on your data, and you own all rights to your data. See LangSmith Terms of Service for more information.How much does LangSmith cost?\\n\\nSee our pricing page for more information, and find a plan that works for you.Ready to start shipping \\u2028reliable agents faster?Get started with tools from the LangChain product suite for every step of the agent development lifecycle.Get a demoSign up for freeProductsLangChainLangSmithLangGraphResourcesGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogExpertsPython DocsLangGraph LangSmithLangChainJS DocsLangGraphLangSmithLangChainCompanyAboutCareersXLinkedInYouTubeMarketing AssetsSecuritySign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Step-2--- Data transformation--(text-chunks)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_spliiter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_spliiter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f072480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.12.0-cp310-cp310-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\sunidhi\\vscode\\langchain\\venv\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\sunidhi\\vscode\\langchain\\venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Using cached faiss_cpu-1.12.0-cp310-cp310-win_amd64.whl (18.2 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d37431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1ec7e112140>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##for step-3 ollama embedding is already present \n",
    "##step--4\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db=FAISS.from_documents(documents,embeddings) \n",
    "db  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db6d40db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c0fa3a38-d98c-46a7-88cc-fd47ebd0bdc8', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content=\"Evaluate your agent's performance.Evaluate your app by saving production traces to datasets â€”\\xa0 then score performance with LLM-as-Judge evaluators. Gather human feedback from subject-matter experts to assess response relevance, correctness, harmfulness, and other criteria.Learn how to run an eval\\n\\n\\nIterate and collaborate on prompts.Experiment with models and prompts in the Playground, and compare outputs across different prompt versions. Any teammate can use the Prompt Canvas UI\\xa0to directly recommend and improve prompts. Create and test a prompt\\n\\n\\nMonitor what matters to the business.Track business-critical metrics like costs, latency, and response quality with live dashboards â€” then get alerted when problems arise and drill into root cause.See how to create a custom dashboard\"),\n",
       " Document(id='ea1568f4-a50c-44c5-8953-17e5f73301e0', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Why LLM apps need different toolingYour app thinks for itself. Understand how.LLM app traces are complex â€” packed with text, tool calls, audio, and images. Youâ€™ll need to find signal in the noise, so you can debug faster and explain behavior with confidence.Testing & observability go hand in hand.There are no guarantees with LLMs. Unified testing & observability lets you turn real user data into evaluation datasets and catch issues that traditional monitoring & testing tools would miss.Itâ€™s not just devs building anymore.From PMs to subject matter experts, everyoneâ€™s involved in building GenAI apps. Close the gap between ideas and working software by making it easy to collaborate across teams â€” whether itâ€™s through writing prompts or providing feedback on experiments.LangSmith is designed for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your'),\n",
       " Document(id='8a5189c4-9aeb-4b99-a750-9e4a3a9f93c1', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Yes, you can log traces to LangSmith using a standard OpenTelemetry client to access all LangSmith features, including tracing, running evals, and prompt engineering. See the docs.How can LangSmith help with observability and evaluation?\\n\\nLangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance â€” including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback. Learn more.I canâ€™t have data leave my environment. Can I self-host LangSmith?\\n\\nYes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our documentation.Where is LangSmith data stored?'),\n",
       " Document(id='a3b07ba7-474f-4d5f-af58-18fe5f9fb060', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your AI\\xa0agents, from design to production.Get the eBookLangSmith FAQsMy application isnâ€™t written in Python or TypeScript. Will LangSmith be helpful?')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"Evaluate your app by saving production traces to datasets â€”  then score performance with LLM-as-Judge evaluators. Gather human feedback\"\n",
    "result=db.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "##for ollama\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "# Initialize the model\n",
    "llm = Ollama(model=\"gemma:2b\")  # Replace with the exact model name you downloaded\n",
    "\n",
    "##similarly you can use hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a23606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Answer the following question based on provided context:\\n<context>\\n{context}  \\n\\n</context>'), additional_kwargs={})])\n",
       "| Ollama(model='gemma:2b')\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retreival chain and document chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "\"\"\"Answer the following question based on provided context:\n",
    "<context>\n",
    "{context}  \n",
    "\n",
    "</context>\"\"\"\n",
    ")\n",
    "prompt\n",
    "##Here when we provide any line from langsmith website that time it we need to get some above and below text in order to get the context\n",
    "##thats why we use it create_stuff_documnets_chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)   ## it will be responsible for providing my prompt template to this specific <context>\n",
    "document_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a86bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, I understand the context and can provide an answer based on the context. \\n\\nBased on the context, I can suggest the following approach for evaluating the app:\\n\\n1. **Record Production Traces:**\\n   - Implement mechanisms to capture and store detailed traces of app usage, including user actions, interactions, and performance metrics.\\n   - Use tools like Firebase Analytics or AppTrace to collect data on user journeys, error messages, and other relevant events.\\n\\n\\n2. **Create LLM Evaluators:**\\n   - Train natural language processing (NLP) models using the collected production traces.\\n   - These models can be used to analyze user feedback, support tickets, and other textual data.\\n   - Use models like GPT, BERT, or XLNet for text comprehension, sentiment analysis, and question-answering.\\n\\n\\n3. **Evaluate Performance Using LLMs:**\\n   - Train LLM-as-Judge evaluators to generate synthetic feedback based on the app's behavior and user responses.\\n   - Use these evaluators to assess the app's performance in terms of user satisfaction, task completion, and other relevant metrics.\\n   - Employ metrics like average rating, completion time, and customer sentiment analysis to evaluate the app.\\n\\n\\n4. **Gather Human Feedback:**\\n   - Conduct surveys or interviews to gather feedback from users about their experience with the app.\\n   - Use online platforms or surveys to collect qualitative data on user experiences and areas for improvement.\\n\\n\\n5. **Combine Evaluation Results:**\\n   - Integrate the evaluation results from LLM analysis, user feedback, and production traces.\\n   - Use data-driven modeling techniques to identify key performance indicators and areas for optimization.\\n\\n\\n6. **Iterative Refinement:**\\n   - Use the insights gained from the evaluation to refine the app's performance and user experience.\\n   - Continue iterating between data collection, model training, and feedback collection to optimize the app's effectiveness.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document     ##creating document manually\n",
    "document_chain.invoke({\n",
    "    \"input\":\"Evaluate your app by saving production traces to datasets â€”  then score performance with LLM-as-Judge evaluators. Gather human feedback\",\n",
    "    \"context\":[Document(page_content=\"Evaluate your app by saving production traces to datasets â€”  then score performance with LLM-as-Judge evaluators. Gather human feedback\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc1f3c",
   "metadata": {},
   "source": [
    "##Retrivers(most important)\n",
    "\n",
    "it is basically an interface ,if anybody ask\n",
    "input---retriever(librarian)--get data from--vectorstoredb(library)\n",
    "we convert vectorstoredb into retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3739fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lets create retreiver\n",
    "retriever=db.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain) ##doc..chain will  be responsible for giving you the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20e3e1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Evaluate your app by saving production traces to datasets â€”  then score performance with LLM-as-Judge evaluators. Gather human feedback',\n",
       " 'context': [Document(id='c0fa3a38-d98c-46a7-88cc-fd47ebd0bdc8', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content=\"Evaluate your agent's performance.Evaluate your app by saving production traces to datasets â€”\\xa0 then score performance with LLM-as-Judge evaluators. Gather human feedback from subject-matter experts to assess response relevance, correctness, harmfulness, and other criteria.Learn how to run an eval\\n\\n\\nIterate and collaborate on prompts.Experiment with models and prompts in the Playground, and compare outputs across different prompt versions. Any teammate can use the Prompt Canvas UI\\xa0to directly recommend and improve prompts. Create and test a prompt\\n\\n\\nMonitor what matters to the business.Track business-critical metrics like costs, latency, and response quality with live dashboards â€” then get alerted when problems arise and drill into root cause.See how to create a custom dashboard\"),\n",
       "  Document(id='ea1568f4-a50c-44c5-8953-17e5f73301e0', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Why LLM apps need different toolingYour app thinks for itself. Understand how.LLM app traces are complex â€” packed with text, tool calls, audio, and images. Youâ€™ll need to find signal in the noise, so you can debug faster and explain behavior with confidence.Testing & observability go hand in hand.There are no guarantees with LLMs. Unified testing & observability lets you turn real user data into evaluation datasets and catch issues that traditional monitoring & testing tools would miss.Itâ€™s not just devs building anymore.From PMs to subject matter experts, everyoneâ€™s involved in building GenAI apps. Close the gap between ideas and working software by making it easy to collaborate across teams â€” whether itâ€™s through writing prompts or providing feedback on experiments.LangSmith is designed for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your'),\n",
       "  Document(id='8a5189c4-9aeb-4b99-a750-9e4a3a9f93c1', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Yes, you can log traces to LangSmith using a standard OpenTelemetry client to access all LangSmith features, including tracing, running evals, and prompt engineering. See the docs.How can LangSmith help with observability and evaluation?\\n\\nLangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance â€” including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback. Learn more.I canâ€™t have data leave my environment. Can I self-host LangSmith?\\n\\nYes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our documentation.Where is LangSmith data stored?'),\n",
       "  Document(id='a3b07ba7-474f-4d5f-af58-18fe5f9fb060', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your AI\\xa0agents, from design to production.Get the eBookLangSmith FAQsMy application isnâ€™t written in Python or TypeScript. Will LangSmith be helpful?')],\n",
       " 'answer': \"The context does not provide information about the application's written language or framework. Therefore, I cannot answer this question from the provided context.\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get the response from llm\n",
    "response=retrieval_chain.invoke({\"input\":\"Evaluate your app by saving production traces to datasets â€”  then score performance with LLM-as-Judge evaluators. Gather human feedback\"})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfb2bb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c0fa3a38-d98c-46a7-88cc-fd47ebd0bdc8', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content=\"Evaluate your agent's performance.Evaluate your app by saving production traces to datasets â€”\\xa0 then score performance with LLM-as-Judge evaluators. Gather human feedback from subject-matter experts to assess response relevance, correctness, harmfulness, and other criteria.Learn how to run an eval\\n\\n\\nIterate and collaborate on prompts.Experiment with models and prompts in the Playground, and compare outputs across different prompt versions. Any teammate can use the Prompt Canvas UI\\xa0to directly recommend and improve prompts. Create and test a prompt\\n\\n\\nMonitor what matters to the business.Track business-critical metrics like costs, latency, and response quality with live dashboards â€” then get alerted when problems arise and drill into root cause.See how to create a custom dashboard\"),\n",
       " Document(id='ea1568f4-a50c-44c5-8953-17e5f73301e0', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Why LLM apps need different toolingYour app thinks for itself. Understand how.LLM app traces are complex â€” packed with text, tool calls, audio, and images. Youâ€™ll need to find signal in the noise, so you can debug faster and explain behavior with confidence.Testing & observability go hand in hand.There are no guarantees with LLMs. Unified testing & observability lets you turn real user data into evaluation datasets and catch issues that traditional monitoring & testing tools would miss.Itâ€™s not just devs building anymore.From PMs to subject matter experts, everyoneâ€™s involved in building GenAI apps. Close the gap between ideas and working software by making it easy to collaborate across teams â€” whether itâ€™s through writing prompts or providing feedback on experiments.LangSmith is designed for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your'),\n",
       " Document(id='8a5189c4-9aeb-4b99-a750-9e4a3a9f93c1', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='Yes, you can log traces to LangSmith using a standard OpenTelemetry client to access all LangSmith features, including tracing, running evals, and prompt engineering. See the docs.How can LangSmith help with observability and evaluation?\\n\\nLangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance â€” including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback. Learn more.I canâ€™t have data leave my environment. Can I self-host LangSmith?\\n\\nYes, we allow customers to self-host LangSmith on our enterprise plan. We deliver the software to run on your Kubernetes cluster, and data will not leave your environment. For more information, check out our documentation.Where is LangSmith data stored?'),\n",
       " Document(id='a3b07ba7-474f-4d5f-af58-18fe5f9fb060', metadata={'source': 'https://www.langchain.com/langsmith', 'title': 'LangSmith', 'description': 'Get your LLM app from prototype to production.', 'language': 'en'}, page_content='for flexibility.Works with or without LangChainHybrid and self-hosted deployment optionsAPI-first and OTEL-compliant to complement existing DevOps investmentsLearn best practices for evaluating your AI\\xa0agents, from design to production.Get the eBookLangSmith FAQsMy application isnâ€™t written in Python or TypeScript. Will LangSmith be helpful?')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26afbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The context does not provide information about the application's written language or framework. Therefore, I cannot answer this question from the provided context.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]\n",
    "## also can use stroutputparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf0392",
   "metadata": {},
   "source": [
    "##To run Ollama in cmd simply write\n",
    "ollama run gemma:2b (whatever the model you have installed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2377f0",
   "metadata": {},
   "source": [
    "ðŸ”¹ Normal chain\n",
    "\n",
    "A normal chain is just LLM + prompt.\n",
    "You pass some text, it fills the prompt, and the LLM answers.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51ab40",
   "metadata": {},
   "source": [
    "ðŸ”¹ Document chain\n",
    "\n",
    "A document chain is a special chain made to handle documents returned by a retriever.\n",
    "When you use retrieval, you donâ€™t get one text string â€” you get a list of Document objects (with .page_content + metadata).\n",
    "The document chainâ€™s job is to:\n",
    "\n",
    "Take that list of documents,\n",
    "\n",
    "Format their text into the {context} placeholder of your prompt,\n",
    "\n",
    "Then send it to the LLM.\n",
    "\n",
    "Thatâ€™s what create_stuff_documents_chain is doing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
