{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40630bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader=TextLoader(\"speech.txt\")\n",
    "documents=loader.load()\n",
    "text_splitter=CharacterTextSplitter(chunk_size=200,chunk_overlap=50)\n",
    "docs=text_splitter.split_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f892d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fb506",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4de523c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f5c742",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OllamaEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings\u001b[38;5;241m=\u001b[39m\u001b[43mOllamaEmbeddings\u001b[49m(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma:2b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m db\u001b[38;5;241m=\u001b[39mFAISS\u001b[38;5;241m.\u001b[39mfrom_documents(docs,embeddings)\n\u001b[0;32m      3\u001b[0m db\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OllamaEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings=OllamaEmbeddings(model=\"gemma:2b\")\n",
    "db=FAISS.from_documents(docs,embeddings)\n",
    "db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\" any query you want\"\n",
    "docs=db.similarity_search(query)\n",
    "docs\n",
    "docs[0]page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74007699",
   "metadata": {},
   "source": [
    "RETRIEVERS\n",
    "we can also convert the vectorstore into retreiver class.This allow us to easilyuse it in other langchain methods,\n",
    "which largely work with retreivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc77eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreivers=db.as_retreivers()\n",
    "docs=retreiver.invoke(query)\n",
    "docs[0]page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129fb1c3",
   "metadata": {},
   "source": [
    "Similarity search method\n",
    "\n",
    "allow you to not just only return the documents but also the distance score of the query to them.\n",
    "the returned score is L2distance.therefore lower score is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_score=db.similarity_search_with_score(query)\n",
    "docs_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors=embeddings.embed_documents(query)\n",
    "embedding_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea55c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_score=db.similarity_search_by_vectors(embeddings_vectors)\n",
    "docs_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ca3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##saving\n",
    "db.save_local(\"faiss_index\") ##to get this in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42036e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load this folder\n",
    "new_db=FAISS.load_local(\"faiss_index\",embeddings,allow_dangerous_deserialization=True)\n",
    "docs=db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb49ea4",
   "metadata": {},
   "source": [
    "Vector store = like a library database that stores your documents in the form of numbers (embeddings).\n",
    "\n",
    "You can ask it: ‚Äúgive me the most similar documents to this query.‚Äù\n",
    "\n",
    "Retriever = like a librarian who knows how to use that database.\n",
    "\n",
    "Instead of you dealing with embeddings and search, you just say: ‚Äúplease find me the relevant documents,‚Äù and the retriever does all the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb70d97",
   "metadata": {},
   "source": [
    "Why convert?\n",
    "\n",
    "Because LangChain‚Äôs tools (like RetrievalQA) don‚Äôt want to deal with the raw database.\n",
    "They just want a librarian (retriever) who can hand them the right documents in a simple way.\n",
    "\n",
    "So:\n",
    "\n",
    "Store your docs in vector store üìö\n",
    "\n",
    "Wrap it in a retriever üë©‚Äçüíº\n",
    "\n",
    "Use the retriever in QA/chat pipelines ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5dd20",
   "metadata": {},
   "source": [
    "##saving\n",
    "Means storing it somewhere permanent so you can reuse it later.\n",
    "\n",
    "##retreive\n",
    "Means retrieving it back from where you saved it, so you can use it again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0206ee8",
   "metadata": {},
   "source": [
    "## We have several databases which we can use \n",
    "here is the link for databases : https://python.langchain.com/v0.2/docs/integrations/vectorstores/\n",
    "\n",
    "FAISS = low-level search engine (just vectors).\n",
    "\n",
    "Chroma = high-level vector database (vectors + metadata + persistence + APIs).\n",
    "Metadata just means ‚Äúdata about data.‚Äù\n",
    "It gives extra information about your main content (the document or text you stored).\n",
    "\n",
    "\"Machine learning is a subset of AI.\"\n",
    "\n",
    "Main data (content): \"Machine learning is a subset of AI.\"\n",
    "\n",
    "Metadata (extra info):\n",
    "\n",
    "Title: \"Intro to AI\"\n",
    "\n",
    "Author: \"Sunidhi\"\n",
    "\n",
    "Date: \"2025-09-22\"\n",
    "\n",
    "Source: \"Wikipedia\"\n",
    "\n",
    "Tags: [\"AI\", \"ML\", \"Basics\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
